{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:Nykole Edward\n",
    "\n",
    "Student ID:108065438\n",
    "\n",
    "GitHub ID:NykoleEdward\n",
    "\n",
    "Kaggle name:Kinwei/Krish\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](kaggle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM19-Lab2-Master Repo](https://github.com/EvaArevalo/DM19-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/t/179d01d4dd984fc5ac45a894822479dd) regarding Emotion Recognition on Twitter. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the score (ie. 20% of 30% )\n",
    "\n",
    "    - **Top 41% - 100%**: Get (101-x)% of the score, where x is your ranking in the leaderboard (ie. (101-x)% of 30% )   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 23rd 11:59 pm, Saturday)__. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/EvaArevalo/DM19-Lab1-Master/blob/master/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb), but make sure to fork the [DM19-Lab2-Homework](https://github.com/EvaArevalo/DM19-Lab2-Homework) repository this time! Also please __DON´T UPLOAD HUGE DOCUMENTS__, please use Git ignore for that.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n",
    "\n",
    "\n",
    "For the purpose of the Kaggle Competition, a Twitter data set provided by the IDEA Lab was crawled with tweets containing specific hashtags. The dataset contains eight classes namely anger, joy, sadness, anticipation, disgust, surprise, trust and fear. These classes were then renamed as “emotions”. The end result of this competition aimed to allow students to perform preprocessing on the dataset in order to clean the data and then to train a model learnt in Data Mining to be able to predict the emotion behind every tweet. \n",
    "\n",
    "I proceeded to import the necessary libraries needed to perform the tasks. I then set file paths to separate the dataset by emotion, ID, and tweets. For the stage of preprocessing of the data, I proceeded to import the datasets and to make it easier to visualize I decided to merge the data by a specific column. This specific column was common to all three datasets. I chose the column “tweet_id”. After that I merged the tweet_id column with data_id then performed a merge of that combination with emotion_id. After that was done I proceeded to separate the training data from the testing data. \n",
    "\n",
    "I proceeded to pickle the train and test data files in order to be able to save them on disk. After loading the pickle file into the workbook, I then decided to make the train set much smaller in order to be able to work with it more comfortably. I then checked the size of the reduced dataset to ensure that it was adequate. I then decided to observe the combined dataset to ensure that the headings were correct and to view a sample of the data in the table. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then went on to perform some exploratory analysis. I first tried a decision tree and tested it out I was able to get 0.35 accuracy so I then proceeded to test out the decision tree by increasing the number to about 30000 the accuracy went up but I still did not meet the benchmark. So, I decided to try the Naïve Bayes Model. I did a frequency chart just to get an idea of how many times the emotions listed above showed up in our dataset. The next step for me was to start my feature engineering.\n",
    "\n",
    "I decided to include some dummy values into the dataset to test the data and the accuracy of it. I went further to add a tokenizer for tweets and then onto using TF-IDF to test the features of the model I would be working with. I then fit some predictions for the model and assigned some predictions and outcome variables. The final steps I took were to perform model fitting where I trained my model using logistic regression. I then fit some predictions and also predicted test values. For the output I assigned results to data frame and output my predictions as a csv file and uploaded to the competition board. \n",
    "\n",
    "This assignment made me notice that the decision tree while it was easier to build the accuracy would not change much even if I increase the number of the sample. It became clear when I utilized the naïve bayes just how much more accurate the results started to be. This method took the most time to figure out but then I was able to increase my accuracy. I wanted to try another model just to see what would happen however I still was having some trouble getting any of the codes to work so I stuck with my naïve bayes as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
